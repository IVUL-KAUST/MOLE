{
    "metadata": {
        "Name": "JaFIn",
        "Link": "https://huggingface.co/datasets/tanabe-jafin/jafin",
        "HF Link": "https://huggingface.co/datasets/tanabe-jafin/jafin",
        "License": "CC BY-SA 4.0",
        "Year": 2024,
        "Language": "jp",
        "Domain": [
            "wikipedia",
            "news articles",
            "captions"
        ],
        "Form": "text",
        "Collection Style": [
            "human annotation",
            "manual curation"
        ],
        "Description": "JaFIn is a Japanese financial instruction dataset for LLMs, containing 1,490 samples collected from various sources including government websites and financial institutions.",
        "Volume": 1490.0,
        "Unit": "sentences",
        "Ethical Risks": "Low",
        "Provider": [
            "Hokkaido University",
            "The University of Tokyo"
        ],
        "Derived From": [],
        "Paper Title": "JaFIn: Japanese Financial Instruction Dataset",
        "Paper Link": "https://example.com/jafin-paper",
        "Script": "mixed",
        "Tokenized": false,
        "Host": "HuggingFace",
        "Access": "Free",
        "Cost": "",
        "Test Split": true,
        "Tasks": [
            "question answering",
            "sentiment analysis",
            "language modeling"
        ],
        "Venue Title": "IEEEtran",
        "Venue Type": "conference",
        "Venue Name": "IEEE Conference",
        "Authors": [
            "Kota Tanabe",
            "Masahiro Suzuki",
            "Hiroki Sakaji",
            "Itsuki Noda"
        ],
        "Affiliations": [
            "Hokkaido University",
            "The University of Tokyo"
        ],
        "Abstract": "We construct an instruction dataset for the large language model (LLM) in the Japanese finance domain. Domain adaptation of language models, including LLMs, is receiving more attention as language models become more popular. This study demonstrates the effectiveness of domain adaptation through instruction tuning. To achieve this, we propose an instruction tuning data in Japanese called JaFIn, the Japanese Financial Instruction Dataset. JaFIn is manually constructed based on multiple data sources, including Japanese government websites, which provide extensive financial knowledge."
    },
    "validation": {
        "ACCESSABILITY": 0.42857142857142855,
        "DIVERSITY": 1.0,
        "CONTENT": 0.875,
        "EVALUATION": 0.3333333333333333,
        "AVERAGE": 0.631578947368421
    },
    "length_forcing": 0.9999999999999999,
    "cost": {
        "cost": 0.00376046,
        "input_tokens": 16549,
        "output_tokens": 469
    },
    "config": {
        "model_name": "meta-llama_llama-4-maverick",
        "few_shot": 0,
        "month": null,
        "year": "2024",
        "keywords": [
            ""
        ],
        "link": "https://arxiv.org/abs/2404.09260"
    },
    "ratio_filling": 1.0,
    "error": null
}